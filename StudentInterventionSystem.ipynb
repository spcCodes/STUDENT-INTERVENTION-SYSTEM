{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The goal of this project is to identify the students who might need intervention before they fail in the exams.It is a classification problem as it contains binary output as whether the student needs intervention or not.\n",
    "The student data is saved as student-data.csv file.\n",
    "\n",
    "\n",
    "In the first step the data is loaded and all the necessary packages of Python are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print(\"Student data read successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA EXPLORATION\n",
    "========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look into the student data and try to gain valuable insights. We would rather find out the following:\n",
    "\n",
    "1. The total number of students in the class.\n",
    "2. The total number of features for each students\n",
    "3. The numebr of students who passed\n",
    "4. The number of students who failed\n",
    "5. The graduation rate of the students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students （number of datapoints): 395\n",
      "Number of features: 30\n",
      "Number of students who passed (graduates): 265\n",
      "Number of students who failed (non-graduates): 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "#Calculating number of students\n",
    "n_students = len(student_data)\n",
    "\n",
    "#Calculate number of features\n",
    "n_features = len(student_data.iloc[0]) - 1\n",
    "\n",
    "#Calculate passing students\n",
    "n_passed = len(student_data[student_data['passed'] == 'yes'])\n",
    "\n",
    "#Calculate failing students\n",
    "n_failed = len(student_data[student_data['passed'] == 'no'])\n",
    "\n",
    "#Calculate graduation rate\n",
    "grad_rate = float(n_passed)/n_students * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of students （number of datapoints): {}\".format(n_students))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of students who passed (graduates): {}\".format(n_passed))\n",
    "print(\"Number of students who failed (non-graduates): {}\".format(n_failed))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA MODELLING ,TRAINING AND TESTING\n",
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains non numeric features which needs to be converted into a numeric one as most machine learning algorithms expect numeric data to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extracting feature columns\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can shere are several non numeric columns that needs to be converted. The column which has just two outputs like yes or no can be directly converted to '1' for yes and '0' for no. \n",
    "\n",
    "For other columns which ahs multiple outputs, one way would be to create as many columns as many outputs that it refelcts and assign 1 to them and 0 to others.This can be done using pandas 'get_dummies' function which does this transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigating each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING AND TESTING DATA SPLITTING\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will randomly shuffle the data and then split in 75:25 ratio and save the data in X_train , X_test , y_train and y_test. So there would be around 300 poimts for training and 95 points for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import any additional functionality you may need here\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Set the number of training points\n",
    "num_train = 300\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "#Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=num_train, test_size=num_test)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose 7 different training models as follows:\n",
    "    \n",
    "1. Gaussian Naive Bayes (GaussianNB)\n",
    "2. Decision Trees\n",
    "3. Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "4. K-Nearest Neighbors (KNeighbors)\n",
    "5. Stochastic Gradient Descent (SGDC)\n",
    "6. Support Vector Machines (SVM)\n",
    "7. Logistic Regression\n",
    "\n",
    "We will then fit the model to varying sizes of training data (100 data points, 200 data points, and 300 data points) and measure the F1 score. The training and testing time of the model is also calculated for choosing the best of the following models looking at all the parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize three helper functions which you can use for training and testing the supervised learning models you've chosen.\n",
    "\n",
    "The helper funstions are:\n",
    "\n",
    "1. trainClassifier - takes as input a classifier and training data and fits the classifier to the data.\n",
    "2. predictLabels - takes as input a fit classifier, features, and a target labeling and makes predictions using the F1 score.\n",
    "3. trainPredict - takes as input a classifier, and the training and testing data, and performs train_clasifier and predict_labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainClassifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predictLabels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def trainPredict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    trainClassifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(predictLabels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(predictLabels(clf, X_test, y_test)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import out supervised learning models stated obove and run trainPredict on the data. We need to do it for different training size as 100, 200 and 300. So in all we will have 21 different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GaussianNB using a training set size of 100. . .\n",
      "Trained model in 0.0014 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 0.4000.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.3146.\n",
      "\n",
      "\n",
      "Training a GaussianNB using a training set size of 200. . .\n",
      "Trained model in 0.0016 seconds\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for training set: 0.8015.\n",
      "Made predictions in 0.0009 seconds.\n",
      "F1 score for test set: 0.6767.\n",
      "\n",
      "\n",
      "Training a GaussianNB using a training set size of 300. . .\n",
      "Trained model in 0.0014 seconds\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for training set: 0.8180.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.7176.\n",
      "\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0011 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.6777.\n",
      "\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0018 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.6230.\n",
      "\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0024 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.6984.\n",
      "\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0121 seconds\n",
      "Made predictions in 0.0012 seconds.\n",
      "F1 score for training set: 0.9926.\n",
      "Made predictions in 0.0013 seconds.\n",
      "F1 score for test set: 0.7068.\n",
      "\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0127 seconds\n",
      "Made predictions in 0.0014 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0012 seconds.\n",
      "F1 score for test set: 0.7121.\n",
      "\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0134 seconds\n",
      "Made predictions in 0.0015 seconds.\n",
      "F1 score for training set: 0.9901.\n",
      "Made predictions in 0.0012 seconds.\n",
      "F1 score for test set: 0.7023.\n",
      "\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0008 seconds\n",
      "Made predictions in 0.0014 seconds.\n",
      "F1 score for training set: 0.8533.\n",
      "Made predictions in 0.0024 seconds.\n",
      "F1 score for test set: 0.7552.\n",
      "\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0012 seconds\n",
      "Made predictions in 0.0032 seconds.\n",
      "F1 score for training set: 0.8327.\n",
      "Made predictions in 0.0018 seconds.\n",
      "F1 score for test set: 0.7500.\n",
      "\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0012 seconds\n",
      "Made predictions in 0.0073 seconds.\n",
      "F1 score for training set: 0.8744.\n",
      "Made predictions in 0.0025 seconds.\n",
      "F1 score for test set: 0.7606.\n",
      "\n",
      "\n",
      "Training a SGDClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0009 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.0000.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.0000.\n",
      "\n",
      "\n",
      "Training a SGDClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0011 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.8182.\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for test set: 0.8129.\n",
      "\n",
      "\n",
      "Training a SGDClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0022 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.8397.\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for test set: 0.7862.\n",
      "\n",
      "\n",
      "Training a SVC using a training set size of 100. . .\n",
      "Trained model in 0.0021 seconds\n",
      "Made predictions in 0.0011 seconds.\n",
      "F1 score for training set: 0.8933.\n",
      "Made predictions in 0.0014 seconds.\n",
      "F1 score for test set: 0.7792.\n",
      "\n",
      "\n",
      "Training a SVC using a training set size of 200. . .\n",
      "Trained model in 0.0045 seconds\n",
      "Made predictions in 0.0033 seconds.\n",
      "F1 score for training set: 0.8639.\n",
      "Made predictions in 0.0018 seconds.\n",
      "F1 score for test set: 0.8027.\n",
      "\n",
      "\n",
      "Training a SVC using a training set size of 300. . .\n",
      "Trained model in 0.0082 seconds\n",
      "Made predictions in 0.0060 seconds.\n",
      "F1 score for training set: 0.8816.\n",
      "Made predictions in 0.0021 seconds.\n",
      "F1 score for test set: 0.7733.\n",
      "\n",
      "\n",
      "Training a LogisticRegression using a training set size of 100. . .\n",
      "Trained model in 0.0017 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.9343.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.7194.\n",
      "\n",
      "\n",
      "Training a LogisticRegression using a training set size of 200. . .\n",
      "Trained model in 0.0026 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.8647.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.7299.\n",
      "\n",
      "\n",
      "Training a LogisticRegression using a training set size of 300. . .\n",
      "Trained model in 0.0033 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.8598.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.7606.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/suman/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Import the three supervised learning models from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#Initializing the  models\n",
    "clf_A = GaussianNB()\n",
    "clf_B = DecisionTreeClassifier(random_state=0)\n",
    "clf_C = RandomForestClassifier(random_state=0)\n",
    "clf_D = KNeighborsClassifier()\n",
    "clf_E = SGDClassifier(random_state=0)\n",
    "clf_F = SVC(random_state=0)\n",
    "clf_G = LogisticRegression(random_state=0)\n",
    "\n",
    "#Set up the training set sizes\n",
    "\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train\n",
    "y_train_300 = y_train\n",
    "\n",
    "#Executing the 'train_predict' function for each classifier and each training set size\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C , clf_D , clf_E , clf_F , clf_G]:\n",
    "    for j in [(X_train_100, y_train_100), (X_train_200, y_train_200), (X_train_300, y_train_300)]:\n",
    "        trainPredict(clf, j[0], j[1], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the models we choose Logistic Regression as our mocel of choice . The reasons are below:\n",
    "    \n",
    "1. Logistic has a better F1 socre of 0.8598 in 300 data points. It also does not suffer from overfitting.\n",
    "2. The training and testing time for logistic regression model is quite less compared to other algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TUNING\n",
    "========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fine tune the chosen model. We will use grid search (GridSearchCV) with at least one important parameter tuned with at least 3 different values. We will need to use the entire training set for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'penalty': ['l2', 'l1'], 'C': [1, 10, 100, 1000]},\n",
      "       pre_dispatch='2*n_jobs', refit=True,\n",
      "       scoring=make_scorer(f1_score, pos_label=yes), verbose=0)\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score:  0.796666666667\n",
      "Made predictions in 0.0012 seconds.\n",
      "Tuned model has a training F1 score of 0.8598.\n",
      "Score:  0.642105263158\n",
      "Made predictions in 0.0008 seconds.\n",
      "Tuned model has a testing F1 score of 0.7606.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    score = clf.score(features, target.values)\n",
    "    end = time()\n",
    "    print(\"Score: \", score)\n",
    "    \n",
    "    # Printing and returning results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "#Create the parameters list you wish to tune\n",
    "parameters = { \"penalty\":[\"l2\",\"l1\"], \n",
    "               \"C\":[1,10,100,1000],\n",
    "              }\n",
    "\n",
    "#Initialize the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "#Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "#Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=f1_scorer)\n",
    "\n",
    "#Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "print(grid_obj)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print(clf)\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print(\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print(\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the model chooses the best parameters and fine tunes the model to give the best accuracy on both training and testing dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
